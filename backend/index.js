

import express from "express";
import cors from "cors";
import dotenv from "dotenv";
import { MongoClient } from "mongodb";


dotenv.config();

const mongoUrl = process.env.MONGO_URI || "mongodb://136.119.60.82:27017/oncoquery";
const dbName = process.env.MONGO_DB_NAME || "oncoquery";
let db;

const app = express();

// middleware
app.use(cors());
app.use(express.json());

// Configuration
const LIMITS = {
Â Â BOT_REVIEWS: 1000,Â Â Â Â Â Â Â Â // Feature 2: Display sample of flagged reviews (reduced from 5000)
Â Â TRENDING_PRODUCTS: 100,Â Â Â // Feature 4: Top trending products (reduced from 500)
Â Â VERIFIED_REVIEWS: 1000,Â Â Â // Feature 5: Sample verified reviews for display (reduced from 5000)
Â Â HELPFUL_REVIEWS: 500Â Â Â Â Â Â // Feature 3: Helpful reviews per query (reduced from 1000)
};

// Early-limit configuration for fast-but-partial aggregations
const EARLY_LIMIT = Math.min(parseInt(process.env.EARLY_LIMIT || "100000", 10), 2000000);

// Query Timeout Configuration
const QUERY_CONFIG = {
Â Â maxTimeMS: 30000,Â Â Â Â Â Â Â Â Â // 30 second timeout for aggregation queries
Â Â allowDiskUse: true,Â Â Â Â Â Â Â // Allow disk usage for large aggregations
Â Â sampleSize: 0.1Â Â Â Â Â Â Â Â Â Â Â // Sample 10% of data for exploratory queries (when ?sample=true)
};

// Cache for dataset date range (to avoid repeated queries)
let datasetMaxDate = null;

// Helper: Get date range going backwards from most recent review
async function getDateRange(collection, weeksBack = 4) {
Â Â // Support dynamic year/month/week
Â Â const args = arguments;
Â Â let weeksBackArg = weeksBack;
Â Â let year, month, week;
Â Â if (args.length > 2) {
Â Â Â Â year = args[2];
Â Â Â Â month = args[3];
Â Â Â Â week = args[4];
Â Â }
Â Â const y = parseInt(year);
Â Â const m = month ? parseInt(month) - 1 : 0;
Â Â const w = week ? parseInt(week) : null;
Â Â const validYear = year && !isNaN(y) && y > 1900 && y < 2100;
Â Â const validMonth = month && !isNaN(parseInt(month)) && parseInt(month) >= 1 && parseInt(month) <= 12;
Â Â const validWeek = week && !isNaN(parseInt(week)) && parseInt(week) >= 1 && parseInt(week) <= 5;
Â Â if (validYear) {
Â Â Â Â let startDateObj, endDateObj;
Â Â Â Â if (validWeek) {
Â Â Â Â Â Â startDateObj = new Date(Date.UTC(y, m, 1));
Â Â Â Â Â Â startDateObj.setUTCDate(1 + (w - 1) * 7);
Â Â Â Â Â Â endDateObj = new Date(startDateObj);
Â Â Â Â Â Â endDateObj.setUTCDate(startDateObj.getUTCDate() + 6);
Â Â Â Â } else if (validMonth) {
Â Â Â Â Â Â startDateObj = new Date(Date.UTC(y, m, 1));
Â Â Â Â Â Â endDateObj = new Date(Date.UTC(y, m + 1, 0));
Â Â Â Â } else {
Â Â Â Â Â Â startDateObj = new Date(Date.UTC(y, 0, 1));
Â Â Â Â Â Â endDateObj = new Date(Date.UTC(y, 11, 31));
Â Â Â Â }
Â Â Â Â if (isNaN(startDateObj.getTime()) || isNaN(endDateObj.getTime())) {
Â Â Â Â Â Â // Fallback to weeksBack if invalid
Â Â Â Â Â Â const endDate = '2015-08-31';
Â Â Â Â Â Â const endDateObj = new Date(endDate);
Â Â Â Â Â Â const startDateObj = new Date(endDateObj);
Â Â Â Â Â Â startDateObj.setDate(startDateObj.getDate() - (weeksBackArg * 7));
Â Â Â Â Â Â const startDate = startDateObj.toISOString().split('T')[0];
Â Â Â Â Â Â return { startDate, endDate };
Â Â Â Â }
Â Â Â Â const startDate = startDateObj.toISOString().split('T')[0];
Â Â Â Â const endDate = endDateObj.toISOString().split('T')[0];
Â Â Â Â return { startDate, endDate };
Â Â }
Â Â // Use the known max date from the dataset
Â Â const endDate = '2015-08-31';
Â Â const endDateObj = new Date(endDate);
Â Â const startDateObj = new Date(endDateObj);
Â Â startDateObj.setDate(startDateObj.getDate() - (weeksBackArg * 7));
Â Â const startDate = startDateObj.toISOString().split('T')[0];
Â Â return { startDate, endDate };
}



// test route
app.get("/", (req, res) => {
Â Â res.send("Backend server is running ðŸš€");
});



// Lazy MongoDB connection (test-friendly)
// NOTE: Index creation has been moved to scripts/setup-indexes-fast.js
// Run that script ONCE before starting the server to avoid blocking requests
async function getDb() {
Â Â if (db) return db;
Â Â const client = new MongoClient(mongoUrl);
Â Â await client.connect();
Â Â db = client.db(dbName);
Â Â 
Â Â // Index creation removed from here to prevent blocking requests
Â Â // Indexes should be created separately using: node scripts/setup-indexes-fast.js
Â Â // This ensures the server starts immediately and can serve requests right away
Â Â 
Â Â return db;
}

// Endpoint to get all distinct product categories
app.get("/api/categories", async (req, res) => {
Â Â try {
Â Â Â Â const database = await getDb();
Â Â Â Â const collection = database.collection("reviews");
Â Â Â Â let categories = await collection.distinct("product_category");
Â Â Â Â 
Â Â Â Â // Generalized filter: remove categories that look like dates, are too long, contain HTML, or are mostly non-alphabetic
Â Â Â Â categories = categories.filter(c => {
Â Â Â Â Â Â if (!c || c === "All") return false;
Â Â Â Â Â Â if (typeof c !== "string") return false;
Â Â Â Â Â Â // Remove if looks like a date (YYYY-MM-DD)
Â Â Â Â Â Â if (/^\d{4}-\d{2}-\d{2}$/.test(c)) return false;
Â Â Â Â Â Â // Remove if contains HTML tags or entities
Â Â Â Â Â Â if (/<[^>]+>|&#\d+;|&[a-z]+;/.test(c)) return false;
Â Â Â Â Â Â // Remove if too long (e.g., > 40 chars)
Â Â Â Â Â Â if (c.length > 40) return false;
Â Â Â Â Â Â // Remove if less than 2 alphabetic characters
Â Â Â Â Â Â if ((c.match(/[a-zA-Z]/g) || []).length < 2) return false;
Â Â Â Â Â Â // Remove if more than 60% of chars are non-alphabetic
Â Â Â Â Â Â const alphaCount = (c.match(/[a-zA-Z]/g) || []).length;
Â Â Â Â Â Â if (alphaCount / c.length < 0.4) return false;
Â Â Â Â Â Â return true;
Â Â Â Â });
Â Â Â Â categories.sort();
    // console.log("Fetched categories from DB:", categories);
Â Â Â Â res.json({ categories: ["All", ...categories] });
Â Â } catch (err) {
Â Â Â Â console.error("Error in /api/categories:", err);
    
Â Â Â Â res.status(500).json({ categories: ["All"], error: "Failed to fetch categories" });
Â Â }
});

// FEATURE 2: BOT REVIEW DETECTION SYSTEM
// Flags suspicious reviews based on detection criteria
// Returns sample of flagged reviews + statistics computed via aggregation
// ULTRA-OPTIMIZED: Remove expensive count, use index-optimized sort, fetch only needed data
// Sort uses compound index: { product_category: 1, review_date: -1 }
app.get("/api/bot-data", async (req, res) => {
Â Â try {
Â Â Â Â const database = await getDb();
Â Â Â Â const collection = database.collection("reviews");
Â Â Â Â 
Â Â Â Â // Pagination support
Â Â Â Â const page = parseInt(req.query.page) || 1;
Â Â Â Â const limit = Math.min(parseInt(req.query.limit) || 25, 100); // Default: 25 per page
Â Â Â Â const skip = (page - 1) * limit;
Â Â Â Â 
Â Â Â Â // Time frame support
  const weeksBack = req.query.weeksBack ? parseInt(req.query.weeksBack) : 1;
Â Â Â Â const { year, month, week, category } = req.query;
Â Â Â Â const { startDate, endDate } = await getDateRange(await getDb().then(db => db.collection("reviews")), weeksBack, year, month, week);
Â Â Â Â const filter = {
Â Â Â Â Â Â review_date: { $gte: startDate, $lte: endDate }
Â Â Â Â };
Â Â Â Â if (category && category !== 'All') {
Â Â Â Â Â Â filter.product_category = category;
Â Â Â Â }

Â Â Â Â // Use compound index when filtering by category, date index otherwise
Â Â Â Â const sortKey = Object.keys(filter).length > 1 && filter.product_category
Â Â Â Â Â Â ? { product_category: 1, review_date: -1 }
Â Â Â Â Â Â : { review_date: -1 };

Â Â Â Â const pipeline = [
Â Â Â Â Â Â { $match: filter },
Â Â Â Â Â Â { $sort: sortKey },
Â Â Â Â Â Â { $limit: skip + limit },Â Â // Limit early to reduce memory
Â Â Â Â Â Â { $skip: skip },
Â Â Â Â Â Â { $limit: limit },
Â Â Â Â Â Â // Lookup review count for each customer_id
Â Â Â Â Â Â { $lookup: {
Â Â Â Â Â Â Â Â Â from: "reviews",
Â Â Â Â Â Â Â Â Â let: { cid: "$customer_id" },
Â Â Â Â Â Â Â Â Â pipeline: [
Â Â Â Â Â Â Â Â Â Â Â { $match: { $expr: { $eq: ["$customer_id", "$$cid"] } } },
Â Â Â Â Â Â Â Â Â Â Â { $count: "count" }
Â Â Â Â Â Â Â Â Â ],
Â Â Â Â Â Â Â Â Â as: "user_review_count"
Â Â Â Â Â Â }},
Â Â Â Â Â Â { $addFields: {
Â Â Â Â Â Â Â Â Â user_review_count: { $ifNull: [ { $arrayElemAt: [ "$user_review_count.count", 0 ] }, 1 ] }
Â Â Â Â Â Â }},
Â Â Â Â Â Â { $project: { product_title: 1, product_category: 1, star_rating: 1, review_date: 1, verified_purchase: 1, review_id: 1, product_id: 1, helpful_votes: 1, total_votes: 1, customer_id: 1, user_review_count: 1 } }
Â Â Â Â ];
Â Â Â Â 
Â Â Â Â // Fetch data only - no count operation (instant response)
Â Â Â Â const [data, estimatedTotal] = await Promise.all([
Â Â Â Â Â Â collection.aggregate(pipeline, { 
Â Â Â Â Â Â Â Â allowDiskUse: QUERY_CONFIG.allowDiskUse,
Â Â Â Â Â Â Â Â hint: Object.keys(filter).length > 0 && filter.product_category 
Â Â Â Â Â Â Â Â Â Â ? { product_category: 1, review_date: -1 }Â Â // Force index usage
Â Â Â Â Â Â Â Â Â Â : undefined
Â Â Â Â Â Â }).toArray(),
Â Â Â Â Â Â // Use estimated count only (no scan, instant)
Â Â Â Â Â Â Object.keys(filter).length === 0 
Â Â Â Â Â Â Â Â ? collection.estimatedDocumentCount()
Â Â Â Â Â Â Â Â : collection.countDocuments(filter).catch(() => collection.estimatedDocumentCount())
Â Â Â Â ]);
Â Â Â Â 
Â Â Â Â const total = estimatedTotal;
Â Â Â Â const totalPages = Math.ceil(total / limit);

Â Â Â Â res.json({ 
Â Â Â Â Â Â total, 
Â Â Â Â Â Â returned: data.length,
Â Â Â Â Â Â page,
Â Â Â Â Â Â limit,
Â Â Â Â Â Â totalPages,
Â Â Â Â Â Â hasMore: page < totalPages,
Â Â Â Â Â Â message: `Showing page ${page} of ${totalPages} (${data.length} reviews)`,
Â Â Â Â Â Â data 
Â Â Â Â });
Â Â } catch (err) {
Â Â Â Â console.error('Error in /api/bot-data:', err);
Â Â Â Â res.status(500).json({ error: "Failed to fetch bot data" });
Â Â }
});

// FEATURE 2: Bot Statistics Endpoint
// Computes detection metrics using aggregation pipeline
// OPTIMIZED: Date range filter + pseudo-random sampling
app.get("/api/bot-stats", async (req, res) => {
Â Â const startTime = Date.now();
Â Â try {
Â Â Â Â const database = await getDb();
Â Â Â Â const collection = database.collection("reviews");
Â Â Â Â 
Â Â Â Â // Get date range (weeksBack from most recent review)
  const weeksBack = parseInt(req.query.weeksBack) || 1; // Default: last 1 week
Â Â Â Â const { startDate, endDate } = await getDateRange(collection, weeksBack);
Â Â Â Â 
Â Â Â Â const dateFilter = { 
Â Â Â Â Â Â review_date: { 
Â Â Â Â Â Â Â Â $gte: startDate,
Â Â Â Â Â Â Â Â $lte: endDate 
Â Â Â Â Â Â } 
Â Â Â Â };
Â Â Â Â 
Â Â Â Â // Get total count first for random offset calculation
Â Â Â Â const totalReviews = await collection.countDocuments(dateFilter);
Â Â Â Â 
Â Â Â Â // Pseudo-random sampling: pick random offset within the range
Â Â Â Â const sampleSize = 1000;
Â Â Â Â const randomOffset = Math.floor(Math.random() * Math.max(0, totalReviews - sampleSize));
Â Â Â Â 
Â Â Â Â const pipeline = [
Â Â Â Â Â Â // 1. MATCH reviews in date range
Â Â Â Â Â Â { $match: dateFilter },
Â Â Â Â Â Â 
Â Â Â Â Â Â // 2. SKIP to random offset
Â Â Â Â Â Â { $skip: randomOffset },
Â Â Â Â Â Â 
Â Â Â Â Â Â // 3. LIMIT to sample size
Â Â Â Â Â Â { $limit: sampleSize },
Â Â Â Â Â Â 
Â Â Â Â Â Â // 4. GROUP by customer_id to count reviews per user
Â Â Â Â Â Â { $group: {
Â Â Â Â Â Â Â Â _id: "$customer_id",
Â Â Â Â Â Â Â Â reviewCount: { $sum: 1 },
Â Â Â Â Â Â Â Â firstDate: { $min: "$review_date" }
Â Â Â Â Â Â }},
Â Â Â Â Â Â 
Â Â Â Â Â Â // 5. FACET to compute both metrics from grouped data
Â Â Â Â Â Â { $facet: {
Â Â Â Â Â Â Â Â oneAndDone: [
Â Â Â Â Â Â Â Â Â Â { $match: { reviewCount: 1 } },
Â Â Â Â Â Â Â Â Â Â { $count: "total" }
Â Â Â Â Â Â Â Â ],
Â Â Â Â Â Â Â Â rapidFire: [
Â Â Â Â Â Â Â Â Â Â { $match: { reviewCount: { $gte: 5 } } },
Â Â Â Â Â Â Â Â Â Â { $count: "total" }
Â Â Â Â Â Â Â Â ]
Â Â Â Â Â Â }}
Â Â Â Â ];

Â Â Â Â const results = await collection.aggregate(pipeline, { 
Â Â Â Â Â Â allowDiskUse: QUERY_CONFIG.allowDiskUse 
Â Â Â Â }).toArray();

Â Â Â Â const [result] = results;
Â Â Â Â const duration = Date.now() - startTime;
Â Â Â Â 
Â Â Â Â res.json({
Â Â Â Â Â Â oneAndDone: result.oneAndDone[0]?.total || 0,
Â Â Â Â Â Â rapidFire: result.rapidFire[0]?.total || 0,
Â Â Â Â Â Â totalReviews,
Â Â Â Â Â Â sampleSize,
Â Â Â Â Â Â randomOffset,
Â Â Â Â Â Â dateRange: { startDate, endDate },
Â Â Â Â Â Â weeksBack,
Â Â Â Â Â Â message: `Bot detection from ${sampleSize.toLocaleString()} sample at offset ${randomOffset.toLocaleString()} (${totalReviews.toLocaleString()} total reviews, ${duration}ms)`
Â Â Â Â });
Â Â } catch (err) {
Â Â Â Â console.error('Error in /api/bot-stats:', err);
Â Â Â Â res.status(500).json({ error: "Failed to compute bot stats" });
Â Â }
});

// FEATURE 4: TRENDING PRODUCTS DISCOVERY ENGINE
// Uses aggregation pipeline to compute trending score = review_count Ã— avg_rating
// OPTIMIZED: Pseudo-random sampling for fast results
app.get("/api/trending-products", async (req, res) => {
Â Â const startTime = Date.now();
Â Â try {
Â Â Â Â const database = await getDb();
Â Â Â Â const collection = database.collection("reviews");
Â Â Â Â 
Â Â Â Â // Pagination support
Â Â Â Â const page = parseInt(req.query.page) || 1;
Â Â Â Â const limit = Math.min(parseInt(req.query.limit) || 25, LIMITS.TRENDING_PRODUCTS); // Default: 25 per page
Â Â Â Â const skip = (page - 1) * limit;
Â Â Â Â 
Â Â Â Â // Dynamic time frame
  const weeksBack = req.query.weeksBack ? parseInt(req.query.weeksBack) : 1;
Â Â Â Â const { year, month, week, category } = req.query;
Â Â Â Â const { startDate, endDate } = await getDateRange(collection, weeksBack, year, month, week);
Â Â Â Â const dateFilter = {
Â Â Â Â Â Â review_date: {
Â Â Â Â Â Â Â Â $gte: startDate,
Â Â Â Â Â Â Â Â $lte: endDate 
Â Â Â Â Â Â }
Â Â Â Â };
Â Â Â Â if (category && category !== 'All') {
Â Â Â Â Â Â dateFilter.product_category = category;
Â Â Â Â }
Â Â Â Â 
Â Â Â Â // Get total count first for random offset calculation
Â Â Â Â const totalReviews = await collection.countDocuments(dateFilter);
Â Â Â Â 
Â Â Â Â // Pseudo-random sampling: pick random offset within the range
Â Â Â Â const sampleSize = 1000; // Sample 25K reviews to find trending products
Â Â Â Â const randomOffset = Math.floor(Math.random() * Math.max(0, totalReviews - sampleSize));
Â Â Â Â 
Â Â Â Â const pipeline = [
Â Â Â Â Â Â // 1. MATCH reviews in date range
Â Â Â Â Â Â { $match: dateFilter },
Â Â Â Â Â Â 
Â Â Â Â Â Â // 2. SKIP to random offset
Â Â Â Â Â Â { $skip: randomOffset },
Â Â Â Â Â Â 
Â Â Â Â Â Â // 3. LIMIT to sample size
Â Â Â Â Â Â { $limit: sampleSize },
Â Â Â Â Â Â 
Â Â Â Â Â Â // 4. GROUP by product to compute stats
Â Â Â Â Â Â { $group: {
Â Â Â Â Â Â Â Â _id: "$product_id",
Â Â Â Â Â Â Â Â product_title: { $first: "$product_title" },
Â Â Â Â Â Â Â Â product_category: { $first: "$product_category" },
Â Â Â Â Â Â Â Â review_count: { $sum: 1 },
Â Â Â Â Â Â Â Â avg_rating: { $avg: { $convert: { input: "$star_rating", to: "int", onError: 0 } } },
Â Â Â Â Â Â Â Â review_dates: { $push: "$review_date" }
Â Â Â Â Â Â }},
Â Â Â Â Â Â 
Â Â Â Â Â Â // 5. SORT by review count (popularity indicator)
Â Â Â Â Â Â { $sort: { review_count: -1 } },
Â Â Â Â Â Â 
Â Â Â Â Â Â // 6. LIMIT before final projection (reduces memory usage)
Â Â Â Â Â Â { $limit: skip + limit },
Â Â Â Â Â Â 
Â Â Â Â Â Â // 7. SKIP for pagination
Â Â Â Â Â Â { $skip: skip },
Â Â Â Â Â Â 
Â Â Â Â Â Â // 8. FORMAT output
Â Â Â Â Â Â { $project: {
Â Â Â Â Â Â Â Â product_id: "$_id",
Â Â Â Â Â Â Â Â product_title: 1,
Â Â Â Â Â Â Â Â product_category: 1,
Â Â Â Â Â Â Â Â review_count: 1,
Â Â Â Â Â Â Â Â avg_rating: { $round: ["$avg_rating", 2] },
Â Â Â Â Â Â Â Â review_dates: 1,
Â Â Â Â Â Â Â Â _id: 0
Â Â Â Â Â Â }}
Â Â Â Â ];
Â Â Â Â 
Â Â Â Â const trending = await collection.aggregate(pipeline, { 
Â Â Â Â Â Â allowDiskUse: QUERY_CONFIG.allowDiskUse 
Â Â Â Â }).toArray();
Â Â Â Â 
Â Â Â Â const duration = Date.now() - startTime;
Â Â Â Â 
Â Â Â Â res.json({
Â Â Â Â Â Â returned: trending.length,
Â Â Â Â Â Â page,
Â Â Â Â Â Â limit,
Â Â Â Â Â Â totalReviews,
Â Â Â Â Â Â sampleSize,
Â Â Â Â Â Â randomOffset,
Â Â Â Â Â Â dateRange: { startDate, endDate },
Â Â Â Â Â Â weeksBack,
Â Â Â Â Â Â message: `Page ${page}: ${trending.length} trending products from ${sampleSize.toLocaleString()} sample at offset ${randomOffset.toLocaleString()} (${totalReviews.toLocaleString()} total reviews, ${duration}ms)`,
Â Â Â Â Â Â data: trending
Â Â Â Â });
Â Â } catch (err) {
Â Â Â Â console.error('Error in /api/trending-products:', err);
Â Â Â Â res.status(500).json({ error: "Failed to fetch trending products" });
Â Â }
});

// FEATURE 1: OVERVIEW STATISTICS
// OPTIMIZED: Ensure review_date index is used - match, sort, then aggregate

// Overview meta endpoint: database size, date range, categories
app.get("/api/overview-meta", async (req, res) => {
Â Â try {
Â Â Â Â const database = await getDb();
Â Â Â Â const collection = database.collection("reviews");
Â Â Â Â const [size, earliestDocs, latestDocs, categories] = await Promise.all([
Â Â Â Â Â Â collection.estimatedDocumentCount(),
Â Â Â Â Â Â collection.find({ review_date: { $regex: /^\d{4}-\d{2}-\d{2}$/ } }).sort({ review_date: 1 }).limit(10).toArray(),
Â Â Â Â Â Â collection.find({ review_date: { $regex: /^\d{4}-\d{2}-\d{2}$/ } }).sort({ review_date: -1 }).limit(10).toArray(),
Â Â Â Â Â Â collection.distinct("product_category")
Â Â Â Â ]);
Â Â Â Â // Debug: log earliestDocs
// Â Â Â Â console.log('DEBUG overview-meta: earliestDocs =', Array.isArray(earliestDocs) ? earliestDocs : 'not an array');
Â Â Â Â // Only consider review_date values that are valid YYYY-MM-DD
Â Â Â Â let earliestDate = null;
Â Â Â Â if (Array.isArray(earliestDocs)) {
Â Â Â Â Â Â const validDates = earliestDocs
Â Â Â Â Â Â Â Â .map(doc => (doc && typeof doc.review_date === 'string' && /^\d{4}-\d{2}-\d{2}$/.test(doc.review_date)) ? doc.review_date : null)
Â Â Â Â Â Â Â Â .filter(Boolean)
Â Â Â Â Â Â Â Â .sort();
Â Â Â Â Â Â if (validDates.length > 0) {
Â Â Â Â Â Â Â Â earliestDate = validDates[0];
Â Â Â Â Â Â }
Â Â Â Â }
Â Â Â Â let latestDate = null;
Â Â Â Â if (Array.isArray(latestDocs)) {
Â Â Â Â Â Â const validDates = latestDocs
Â Â Â Â Â Â Â Â .map(doc => (doc && typeof doc.review_date === 'string' && /^\d{4}-\d{2}-\d{2}$/.test(doc.review_date)) ? doc.review_date : null)
Â Â Â Â Â Â Â Â .filter(Boolean)
Â Â Â Â Â Â Â Â .sort();
Â Â Â Â Â Â if (validDates.length > 0) {
Â Â Â Â Â Â Â Â latestDate = validDates[validDates.length - 1];
Â Â Â Â Â Â }
Â Â Â Â }
// Â Â Â Â console.log('DEBUG overview-meta: computed earliestDate =', earliestDate, 'latestDate =', latestDate);
Â Â Â Â const filteredCategories = (categories || []).filter(c => {
Â Â Â Â Â Â if (!c || c === "All") return false;
Â Â Â Â Â Â if (typeof c !== "string") return false;
Â Â Â Â Â Â if (/^\d{4}-\d{2}-\d{2}$/.test(c)) return false;
Â Â Â Â Â Â if (/<[^>]+>|&#\d+;|&[a-z]+;/.test(c)) return false;
Â Â Â Â Â Â if (c.length > 40) return false;
Â Â Â Â Â Â if ((c.match(/[a-zA-Z]/g) || []).length < 2) return false;
Â Â Â Â Â Â const alphaCount = (c.match(/[a-zA-Z]/g) || []).length;
Â Â Â Â Â Â if (alphaCount / c.length < 0.4) return false;
Â Â Â Â Â Â return true;
Â Â Â Â });
Â Â Â Â res.json({
Â Â Â Â Â Â size,
Â Â Â Â Â Â earliestDate,
Â Â Â Â Â Â latestDate,
Â Â Â Â Â Â categories: ["All", ...filteredCategories.sort()]
Â Â Â Â });
Â Â } catch (err) {
Â Â Â Â console.error("Error in /api/overview-meta:", err);
Â Â Â Â res.status(500).json({ error: "Failed to fetch overview meta" });
Â Â }
});

// FEATURE 5: VERIFIED PURCHASE IMPACT ANALYSIS
// OPTIMIZED: Pseudo-random sampling for fast results
app.get("/api/verified-analysis", async (req, res) => {
Â Â const startTime = Date.now();
Â Â try {
Â Â Â Â const database = await getDb();
Â Â Â Â const collection = database.collection("reviews");
Â Â Â Â // Pagination support
Â Â Â Â const page = parseInt(req.query.page) || 1;
Â Â Â Â const limit = Math.min(parseInt(req.query.limit) || 5, 100);
Â Â Â Â const skip = (page - 1) * limit;
Â Â Â Â // Dynamic time frame
  const weeksBack = req.query.weeksBack ? parseInt(req.query.weeksBack) : 1;
Â Â Â Â const { year, month, week, category } = req.query;
Â Â Â Â const { startDate, endDate } = await getDateRange(collection, weeksBack, year, month, week);
Â Â Â Â const dateFilter = {
Â Â Â Â Â Â review_date: {
Â Â Â Â Â Â Â Â $gte: startDate,
Â Â Â Â Â Â Â Â $lte: endDate
Â Â Â Â Â Â }
Â Â Â Â };
Â Â Â Â // Add category filter if provided and not 'All'
Â Â Â Â if (category && category !== 'All') {
Â Â Â Â Â Â dateFilter.product_category = category;
Â Â Â Â }
Â Â Â Â // Get total count for random offset
Â Â Â Â const totalReviews = await collection.countDocuments(dateFilter);
Â Â Â Â // Pseudo-random sampling: pick random offset within the range
Â Â Â Â const sampleSize = 1000;
Â Â Â Â const randomOffset = Math.floor(Math.random() * Math.max(0, totalReviews - sampleSize));
Â Â Â Â const [verifiedReviews, stats] = await Promise.all([
Â Â Â Â Â Â // Get sample of verified reviews (filter AFTER sampling for consistency)
Â Â Â Â Â Â collection.aggregate([
Â Â Â Â Â Â Â Â { $match: dateFilter },
Â Â Â Â Â Â Â Â { $skip: randomOffset },
Â Â Â Â Â Â Â Â { $limit: sampleSize },
Â Â Â Â Â Â Â Â { $match: { verified_purchase: "Y" } },
Â Â Â Â Â Â Â Â { $project: { product_title: 1, product_category: 1, star_rating: 1, review_date: 1, review_id: 1, product_id: 1 } },
Â Â Â Â Â Â Â Â { $limit: skip + limit },
Â Â Â Â Â Â Â Â { $skip: skip },
Â Â Â Â Â Â Â Â { $limit: limit }
Â Â Â Â Â Â ]).toArray(),
Â Â Â Â Â Â // Count verified vs unverified using same sampling approach
Â Â Â Â Â Â collection.aggregate([
Â Â Â Â Â Â Â Â { $match: dateFilter },
Â Â Â Â Â Â Â Â { $skip: randomOffset },
Â Â Â Â Â Â Â Â { $limit: sampleSize },
Â Â Â Â Â Â Â Â { $group: {
Â Â Â Â Â Â Â Â Â Â _id: "$verified_purchase",
Â Â Â Â Â Â Â Â Â Â count: { $sum: 1 }
Â Â Â Â Â Â Â Â }}
Â Â Â Â Â Â ]).toArray()
Â Â Â Â ]);
Â Â Â Â const verifiedCount = stats.find(s => s._id === 'Y')?.count || 0;
Â Â Â Â const unverifiedCount = stats.find(s => s._id === 'N')?.count || 0;
Â Â Â Â const totalCount = verifiedCount + unverifiedCount;
Â Â Â Â const duration = Date.now() - startTime;
Â Â Â Â const totalPages = Math.ceil(verifiedCount / limit);
Â Â Â Â res.json({
Â Â Â Â Â Â total: verifiedCount,
Â Â Â Â Â Â returned: verifiedReviews.length,
Â Â Â Â Â Â page,
Â Â Â Â Â Â limit,
Â Â Â Â Â Â totalReviews,
Â Â Â Â Â Â sampleSize,
Â Â Â Â Â Â randomOffset,
Â Â Â Â Â Â totalPages,
Â Â Â Â Â Â hasMore: page < totalPages,
Â Â Â Â Â Â dateRange: { startDate, endDate },
Â Â Â Â Â Â weeksBack,
Â Â Â Â Â Â verificationRate: totalCount > 0 ? ((verifiedCount / totalCount) * 100).toFixed(1) + '%' : 'N/A',
Â Â Â Â Â Â message: `${verifiedReviews.length} verified reviews from ${sampleSize.toLocaleString()} sample at offset ${randomOffset.toLocaleString()} (${totalReviews.toLocaleString()} total, ${duration}ms)`,
Â Â Â Â Â Â data: verifiedReviews
Â Â Â Â });
Â Â } catch (err) {
Â Â Â Â console.error('Error in /api/verified-analysis:', err);
Â Â Â Â res.status(500).json({ error: "Failed to fetch verified analysis data" });
Â Â }
});

// FEATURE 5: VERIFIED VS NON-VERIFIED COMPARISON STATISTICS
// OPTIMIZED: Pseudo-random sampling for fast results
app.get("/api/verified-stats", async (req, res) => {
Â Â const startTime = Date.now();
Â Â try {
Â Â Â Â const database = await getDb();
Â Â Â Â const collection = database.collection("reviews");
Â Â Â Â // Pagination support
Â Â Â Â const page = parseInt(req.query.page) || 1;
Â Â Â Â const limit = Math.min(parseInt(req.query.limit) || 5, 100);
Â Â Â Â const skip = (page - 1) * limit;
Â Â Â Â // Dynamic time frame
  const weeksBack = req.query.weeksBack ? parseInt(req.query.weeksBack) : 1;
Â Â Â Â const { year, month, week, category } = req.query;
Â Â Â Â const { startDate, endDate } = await getDateRange(collection, weeksBack, year, month, week);
Â Â Â Â const dateFilter = {
Â Â Â Â Â Â review_date: {
Â Â Â Â Â Â Â Â $gte: startDate,
Â Â Â Â Â Â Â Â $lte: endDate 
Â Â Â Â Â Â } 
Â Â Â Â };
Â Â Â Â // Add category filter if provided and not 'All'
Â Â Â Â if (category && category !== 'All') {
Â Â Â Â Â Â dateFilter.product_category = category;
Â Â Â Â }
Â Â Â Â // Get total count for random offset
Â Â Â Â const totalReviews = await collection.countDocuments(dateFilter);
Â Â Â Â // Pseudo-random sampling
Â Â Â Â const sampleSize = 10000;
Â Â Â Â const randomOffset = Math.floor(Math.random() * Math.max(0, totalReviews - sampleSize));
Â Â Â Â const pipeline = [
Â Â Â Â Â Â // 1. MATCH date range and category
Â Â Â Â Â Â { $match: dateFilter },
Â Â Â Â Â Â // 2. SKIP to random offset
Â Â Â Â Â Â { $skip: randomOffset },
Â Â Â Â Â Â // 3. LIMIT to sample size
Â Â Â Â Â Â { $limit: sampleSize },
Â Â Â Â Â Â // 4. GROUP by verified_purchase
Â Â Â Â Â Â { $group: {
Â Â Â Â Â Â Â Â _id: "$verified_purchase",
Â Â Â Â Â Â Â Â count: { $sum: 1 },
Â Â Â Â Â Â Â Â avgRating: { $avg: { $convert: { input: "$star_rating", to: "int", onError: 0 } } },
Â Â Â Â Â Â Â Â avgHelpful: { $avg: { $convert: { input: "$helpful_votes", to: "int", onError: 0 } } }
Â Â Â Â Â Â }},
Â Â Â Â Â Â // 5. FORMAT output
Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â $project: {
Â Â Â Â Â Â Â Â Â Â verified: "$_id",
Â Â Â Â Â Â Â Â Â Â count: 1,
Â Â Â Â Â Â Â Â Â Â avgRating: { $round: ["$avgRating", 2] },
Â Â Â Â Â Â Â Â Â Â avgHelpful: { $round: ["$avgHelpful", 2] },
Â Â Â Â Â Â Â Â Â Â _id: 0
Â Â Â Â Â Â Â Â }
Â Â Â Â Â Â },
Â Â Â Â Â Â // 6. Pagination for stats array (simulate pagination on grouped results)
Â Â Â Â Â Â { $limit: skip + limit },
Â Â Â Â Â Â { $skip: skip },
Â Â Â Â Â Â { $limit: limit }
Â Â Â Â ];
Â Â Â Â const results = await collection.aggregate(pipeline, { 
Â Â Â Â Â Â allowDiskUse: QUERY_CONFIG.allowDiskUse 
Â Â Â Â }).toArray();
Â Â Â Â const duration = Date.now() - startTime;
Â Â Â Â const totalStats = results.length > 0 ? results.reduce((acc, cur) => acc + (cur.count || 0), 0) : 0;
Â Â Â Â const totalPages = Math.ceil(totalStats / limit);
Â Â Â Â res.json({
Â Â Â Â Â Â comparisonStats: results,
Â Â Â Â Â Â page,
Â Â Â Â Â Â limit,
Â Â Â Â Â Â totalReviews,
Â Â Â Â Â Â sampleSize,
Â Â Â Â Â Â randomOffset,
Â Â Â Â Â Â totalPages,
Â Â Â Â Â Â hasMore: page < totalPages,
Â Â Â Â Â Â dateRange: { startDate, endDate },
Â Â Â Â Â Â weeksBack,
Â Â Â Â Â Â message: `Verified vs unverified from ${sampleSize.toLocaleString()} sample at offset ${randomOffset.toLocaleString()} (${totalReviews.toLocaleString()} total, ${duration}ms)`
Â Â Â Â });
Â Â } catch (err) {
Â Â Â Â console.error('Error in /api/verified-stats:', err);
Â Â Â Â res.status(500).json({ error: "Failed to fetch verified comparison stats" });
Â Â }
});

app.get("/api/helpful-reviews", async (req, res) => {
  const startTime = Date.now();
  try {
    const database = await getDb();
    const collection = database.collection("reviews");
    
    // Pagination support
    const page = parseInt(req.query.page) || 1;
    const limit = Math.min(parseInt(req.query.limit) || 5, 100);
    const skip = (page - 1) * limit;
    
    Â Â Â Â // Dynamic time frame
    const weeksBack = req.query.weeksBack ? parseInt(req.query.weeksBack) : 1;
    Â Â Â Â const { year, month, week } = req.query;
    Â Â Â Â const { startDate, endDate } = await getDateRange(collection, weeksBack, year, month, week);
    
    const dateFilter = {
      review_date: { $gte: startDate, $lte: endDate }
    };
    
    // Category filter
    if (req.query.category && req.query.category !== 'All') {
      dateFilter.product_category = req.query.category;
    }
    
    // Get total count for deterministic sampling
    const totalReviews = await collection.countDocuments(dateFilter);
    
    // Use deterministic "random" offset based on query parameters
    // This ensures all pages use the same sample for consistent sorting
    const sampleSize = 1000;
    const queryKey = `${startDate}-${endDate}-${req.query.category || 'All'}`;
    // Simple hash function to generate consistent offset
    let hash = 0;
    for (let i = 0; i < queryKey.length; i++) {
      const char = queryKey.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // Convert to 32bit integer
    }
    const randomOffset = Math.abs(hash) % Math.max(1, totalReviews - sampleSize);
    
    // Count pipeline to get total matching items (after sampling and filtering)
    const countPipeline = [
      // 1. MATCH reviews in date range (and category if provided)
      { $match: dateFilter },
      
      // 2. Sort by _id for consistent ordering before sampling
      { $sort: { _id: 1 } },
      
      // 3. SKIP to deterministic offset (consistent sampling)
      { $skip: randomOffset },
      
      // 4. LIMIT to sample size
      { $limit: sampleSize },
      
      // 5. Convert vote fields to numbers for proper filtering
      { $addFields: {
        helpful_votes_num: { 
          $convert: { 
            input: "$helpful_votes", 
            to: "int", 
            onError: 0,
            onNull: 0
          } 
        },
        total_votes_num: { 
          $convert: { 
            input: "$total_votes", 
            to: "int", 
            onError: 0,
            onNull: 0
          } 
        }
      }},
      
      // 6. Filter by votes AFTER conversion
      { $match: { total_votes_num: { $gte: 5 } } },
      
      // 7. Count total matching items
      { $count: "total" }
    ];
    
    const dataPipeline = [
      // 1. MATCH reviews in date range (and category if provided)
      { $match: dateFilter },
      
      // 2. Sort by _id for consistent ordering before sampling
      { $sort: { _id: 1 } },
      
      // 3. SKIP to deterministic offset (consistent sampling)
      { $skip: randomOffset },
      
      // 4. LIMIT to sample size
      { $limit: sampleSize },
      
      // 5. Convert vote fields to numbers for proper filtering and sorting
      { $addFields: {
        helpful_votes_num: { 
          $convert: { 
            input: "$helpful_votes", 
            to: "int", 
            onError: 0,
            onNull: 0
          } 
        },
        total_votes_num: { 
          $convert: { 
            input: "$total_votes", 
            to: "int", 
            onError: 0,
            onNull: 0
          } 
        }
      }},
      
      // 6. Filter by votes AFTER conversion
      { $match: { total_votes_num: { $gte: 5 } } },
      
      // 7. Sort using converted numeric fields (sort within the consistent sample)
      { $sort: { helpful_votes_num: -1, total_votes_num: -1 } },
      
      // 8. Apply pagination (skip and limit after sorting)
      { $skip: skip },
      { $limit: limit },
      
      // 8. Project final fields
      { $project: { 
        product_title: 1, product_category: 1, star_rating: 1, 
        review_headline: 1, review_body: 1, review_date: 1, 
        review_id: 1, product_id: 1, 
        helpful_votes: 1,  // Keep original field
        total_votes: 1,     // Keep original field
        customer_id: 1
      }}
    ];
    
    // Get count and data in parallel
    const [countResult, data] = await Promise.all([
      collection.aggregate(countPipeline, { 
        allowDiskUse: QUERY_CONFIG.allowDiskUse
      }).toArray(),
      collection.aggregate(dataPipeline, { 
        allowDiskUse: QUERY_CONFIG.allowDiskUse
      }).toArray()
    ]);
    
    const totalMatchingItems = countResult[0]?.total || 0;
    const totalPages = Math.ceil(totalMatchingItems / limit);
    const duration = Date.now() - startTime;
    
    res.json({
      returned: data.length,
      page,
      limit,
      totalMatchingItems,
      totalPages,
      hasMore: page < totalPages && data.length === limit,
      dateRange: { startDate, endDate },
      weeksBack,
      message: `${data.length} most helpful reviews from ${sampleSize.toLocaleString()} sample (${totalMatchingItems.toLocaleString()} total matching, ${duration}ms)`,
      data
    });
  } catch (err) {
    console.error("Error in /api/helpful-reviews:", err);
    res.status(500).json({ error: "Failed to fetch helpful reviews", details: err.message });
  }
});

app.get("/api/controversial-reviews", async (req, res) => {
  const startTime = Date.now();
  try {
    const database = await getDb();
    const collection = database.collection("reviews");
    
    // Pagination support
    const page = parseInt(req.query.page) || 1;
    const limit = Math.min(parseInt(req.query.limit) || 5, 100);
    const skip = (page - 1) * limit;
    
    Â Â Â Â // Dynamic time frame
    Â Â Â Â const weeksBack = req.query.weeksBack ? parseInt(req.query.weeksBack) : 5;
    Â Â Â Â const { year, month, week } = req.query;
    Â Â Â Â const { startDate, endDate } = await getDateRange(collection, weeksBack, year, month, week);
    
    const dateFilter = {
      review_date: { $gte: startDate, $lte: endDate }
    };
    
    // Category filter
    if (req.query.category && req.query.category !== 'All') {
      dateFilter.product_category = req.query.category;
    }
    
    // Get total count for deterministic sampling
    const totalReviews = await collection.countDocuments(dateFilter);
    
    // Use deterministic "random" offset based on query parameters
    // This ensures all pages use the same sample for consistent sorting
    const sampleSize = 1000;
    const queryKey = `${startDate}-${endDate}-${req.query.category || 'All'}`;
    // Simple hash function to generate consistent offset
    let hash = 0;
    for (let i = 0; i < queryKey.length; i++) {
      const char = queryKey.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // Convert to 32bit integer
    }
    const randomOffset = Math.abs(hash) % Math.max(1, totalReviews - sampleSize);
    
    // Count pipeline to get total matching items (after sampling and filtering)
    const countPipeline = [
      // 1. MATCH reviews in date range (and category if provided)
      { $match: dateFilter },
      // 2. Sort by _id for consistent ordering before sampling
      { $sort: { _id: 1 } },
      // 3. SKIP to deterministic offset (consistent sampling)
      { $skip: randomOffset },
      // 4. LIMIT to sample size
      { $limit: sampleSize },
      // 5. Convert vote fields to numbers
      { $addFields: {
        helpful_votes_num: { 
          $convert: { 
            input: "$helpful_votes", 
            to: "int", 
            onError: 0,
            onNull: 0
          } 
        },
        total_votes_num: { 
          $convert: { 
            input: "$total_votes", 
            to: "int", 
            onError: 0,
            onNull: 0
          } 
        }
      }},
      // 6. Calculate unhelpful votes using already converted fields
      { $addFields: {
        unhelpful_votes_num: {
          $subtract: ["$total_votes_num", "$helpful_votes_num"]
        }
      }},
      // 7. Filter by votes AFTER conversion
      { $match: { total_votes_num: { $gte: 10 } } },
      // 8. Count total matching items
      { $count: "total" }
    ];
    
    const dataPipeline = [
      // 1. MATCH reviews in date range (and category if provided)
      { $match: dateFilter },
      // 2. Sort by _id for consistent ordering before sampling
      { $sort: { _id: 1 } },
      // 3. SKIP to deterministic offset (consistent sampling)
      { $skip: randomOffset },
      // 4. LIMIT to sample size
      { $limit: sampleSize },
      // 5. Convert vote fields to numbers
      { $addFields: {
        helpful_votes_num: { 
          $convert: { 
            input: "$helpful_votes", 
            to: "int", 
            onError: 0,
            onNull: 0
          } 
        },
        total_votes_num: { 
          $convert: { 
            input: "$total_votes", 
            to: "int", 
            onError: 0,
            onNull: 0
          } 
        }
      }},
      // 6. Calculate unhelpful votes using already converted fields
      { $addFields: {
        unhelpful_votes_num: {
          $subtract: ["$total_votes_num", "$helpful_votes_num"]
        }
      }},
      // 7. Filter by votes AFTER conversion
      { $match: { total_votes_num: { $gte: 10 } } },
      // 8. Calculate controversy_score BEFORE sorting (percentage of unhelpful votes)
      { $addFields: {
        controversy_score: {
          $cond: [
            { $gt: ["$total_votes_num", 0] },
            { $round: [{ $multiply: [{ $divide: ["$unhelpful_votes_num", "$total_votes_num"] }, 100] }, 1] },
            0
          ]
        }
      }},
      // 9. Sort by controversy_score descending (most controversial first), then by total_votes descending
      { $sort: { controversy_score: -1, total_votes_num: -1 } },
      // 10. Apply pagination
      { $skip: skip },
      { $limit: limit },
      // 11. Project final fields
      { $project: {
        product_title: 1, product_category: 1, star_rating: 1,
        review_headline: 1, review_body: 1, review_date: 1,
        review_id: 1, product_id: 1, 
        helpful_votes: 1,  // Keep original
        total_votes: 1,    // Keep original
        customer_id: 1,
        unhelpful_votes: "$unhelpful_votes_num",
        controversy_score: 1  // Use already calculated value
      }}
    ];
    
    // Get count and data in parallel
    const [countResult, data] = await Promise.all([
      collection.aggregate(countPipeline, { 
        allowDiskUse: QUERY_CONFIG.allowDiskUse
      }).toArray(),
      collection.aggregate(dataPipeline, { 
        allowDiskUse: QUERY_CONFIG.allowDiskUse
      }).toArray()
    ]);
    
    const totalMatchingItems = countResult[0]?.total || 0;
    const totalPages = Math.ceil(totalMatchingItems / limit);
    const duration = Date.now() - startTime;
    
    res.json({
      returned: data.length,
      page,
      limit,
      totalMatchingItems,
      totalPages,
      hasMore: page < totalPages && data.length === limit,
      dateRange: { startDate, endDate },
      weeksBack,
      message: `${data.length} controversial reviews from ${sampleSize.toLocaleString()} sample (${totalMatchingItems.toLocaleString()} total matching, ${duration}ms)`,
      data
    });
  } catch (err) {
    console.error("Error in /api/controversial-reviews:", err);
    res.status(500).json({ error: "Failed to fetch controversial reviews", details: err.message });
  }
});


const PORT = process.env.PORT || 5001;

app.listen(PORT, () => {
Â Â console.log(`Server running on port ${PORT}`);
});